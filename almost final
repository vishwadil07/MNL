rm(list = ls())

library(nnet)
library(mlogit)
library(scales)

# full.data <- read.csv("eBay_Completes_US data_E.csv")
# data <- full.data[c("SN","respid" ,"a1_1", "a4_a19_1",  
#                     "a4_a19_2",  "a4_a19_3",  "a4_a19_4",  "a4_a19_5",
#                     "a4_a19_6")]

rename <- function(df1,u1,v1){
  oldnames=u1
  newnames=v1
  for(i in 1:length(u1))names(df1)[names(df1)==oldnames[i]]=newnames[i]
  return(df1)
}

Count <- function(x,y,z) {
  count = 0
  for(i in 1:length(x))
  {
    if(x[i] == y | x[i] == z)
    {
      count = count + 1
    }
  }
  return(count)
}

nps <- function(df1,df2,v){
  
  data.n <- df1[v]
  coeff.d <- as.matrix(df2[1,3:8])
  data.nm <- as.matrix(data.n[,3:8])
  sump.d <- vector()
  for(i in 1:500){
    sump.d[i] <- exp(rowSums(data.nm[i,] * coeff.d) + coeff[1,2])
  }
  
  coeff.p <- as.matrix(coeff[2,3:8])
  data.nm <- as.matrix(data.n[,3:8])
  sump.p <- vector()
  for(i in 1:500){
    sump.p[i] <- exp(rowSums(data.nm[i,] * coeff.p) + coeff[2,2])
  }
  
  p0 <- (1/(1+sump.p+sump.d))
  p1 <- sump.p*p0
  p2 <- 1-p0-p1
  
  prob <- cbind(p0,p1,p2)
  
  pred.y.x1 <- (ifelse(apply(prob,1,max)==p1,1,
                       ifelse(apply(prob,1,max)==p0,0,
                              ifelse(apply(prob,1,max)==p2,-1,NA))))
  
  new.nps <- round(((Count(pred.y.x1,1,5) - Count(pred.y.x1,-1,5))/500),3)
  return(new.nps)
}

############### Increasing percentage #################

increase.x <- function(df,u,c){
  
  x <- df$u
  x.n <- u
  new.x <- c
  
  i <- 1
  while(new.x != c){
    random <- sample(1:500,1)
    a <- ifelse(df$SN %in% random,df$SN,0)
    x.n <- ifelse((a == 0 | x.n == 10),
                  x,x.n + 1)
    new.x <- round((Count(x.n,9,10)/dim(df)[1]),2)
    i <-  i + 1
  }
  
  df$x.n <- x.n
  return(df$x.n)
}


data <- read.csv("USeBay.csv")

############## Converting the dependent ##############

data$y.obs <- as.factor(ifelse(data$a1_1 <= 6,-1,ifelse((data$a1_1 == 7 | data$a1_1 == 8),0,
                                                        ifelse(data$a1_1 > 8,1,NA))))

with(data, table(y.obs, a1_1))

data$y.obs.rl <- relevel(data$y.obs, ref = "0")

init.mnl <- multinom(y.obs.rl ~ a4_a19_1 + a4_a19_2 + a4_a19_3 + a4_a19_4 + a4_a19_5
                     + a4_a19_6, data)

init.data <- data
init.data$y.pred <- predict(init.mnl)

fitted <- init.mnl$fitted.values


summary(init.mnl)

init.nps <- round((Count(init.data$y.pred,1,5) - Count(init.data$y.pred,-1,5))/dim(init.data)[1],3)

init.a4_a19_1 <- round((Count(init.data$a4_a19_1,9,10)/dim(init.data)[1]),2)
init.a4_a19_2 <- round((Count(init.data$a4_a19_2,9,10)/dim(init.data)[1]),2)
init.a4_a19_3 <- round((Count(init.data$a4_a19_3,9,10)/dim(init.data)[1]),2)
init.a4_a19_4 <- round((Count(init.data$a4_a19_4,9,10)/dim(init.data)[1]),2)
init.a4_a19_5 <- round((Count(init.data$a4_a19_5,9,10)/dim(init.data)[1]),2)
init.a4_a19_6 <- round((Count(init.data$a4_a19_6,9,10)/dim(init.data)[1]),2)

cutoff.a4_a19_1 <- round((init.a4_a19_1 +  (init.a4_a19_1/10)),2)
cutoff.a4_a19_2 <- round((init.a4_a19_2 +  (init.a4_a19_2/10)),2)
cutoff.a4_a19_3 <- round((init.a4_a19_3 +  (init.a4_a19_3/10)),2)
cutoff.a4_a19_4 <- round((init.a4_a19_4 +  (init.a4_a19_4/10)),2)
cutoff.a4_a19_5 <- round((init.a4_a19_5 +  (init.a4_a19_5/10)),2)
cutoff.a4_a19_6 <- round((init.a4_a19_6 +  (init.a4_a19_6/10)),2)

############### Increasing percentage #################
a4_a19_6 <- data$a4_a19_6
a4_a19_6.n <- a4_a19_6
new.a4_a19_6 <- init.a4_a19_6
# 
# i <- 1
# while(new.a4_a19_6 != cutoff.a4_a19_6){
#   random <- sample(1:500,1)
#   a <- ifelse(data$SN %in% random,data$SN,0)
#   a4_a19_6.n <- ifelse((a == 0 | a4_a19_6.n == 10),
#                        a4_a19_6.n,a4_a19_6.n + 1)
#   new.a4_a19_6 <- round((Count(a4_a19_6.n,9,10)/dim(data)[1]),2)
#   i <-  i + 1
# }
# 
# data$a4_a19_6.n <- a4_a19_6.n

x1.n1 <- increase.x(data,a4_a19_6,cutoff.a4_a19_6)
x1.n2 <- increase.x(data,a4_a19_6,cutoff.a4_a19_6)
x1.n3 <- increase.x(data,a4_a19_6,cutoff.a4_a19_6)
x1.n4 <- increase.x(data,a4_a19_6,cutoff.a4_a19_6)
x1.n <- cbind(x1.n1,x1.n2,x1.n3,x1.n4)




coeff <- read.csv("probability calculation.csv")

new.nps.1 <- nps(init.data,coeff,c("SN","respid" , "a4_a19_1.n",  
                           "a4_a19_2",  "a4_a19_3",  "a4_a19_4",  "a4_a19_5",
                           "a4_a19_6"))

new.nps.2 <- nps(init.data,coeff,c("SN","respid" , "a4_a19_1",  
                                   "a4_a19_2.n",  "a4_a19_3",  "a4_a19_4",  "a4_a19_5",
                                   "a4_a19_6"))

new.nps.3 <- nps(init.data,coeff,c("SN","respid" , "a4_a19_1",  
                                   "a4_a19_2",  "a4_a19_3.n",  "a4_a19_4",  "a4_a19_5",
                                   "a4_a19_6"))

new.nps.4 <- nps(init.data,coeff,c("SN","respid" , "a4_a19_1",  
                                   "a4_a19_2",  "a4_a19_3",  "a4_a19_4.n",  "a4_a19_5",
                                   "a4_a19_6"))

new.nps.5 <- nps(init.data,coeff,c("SN","respid" , "a4_a19_1",  
                                   "a4_a19_2",  "a4_a19_3",  "a4_a19_4",  "a4_a19_5.n",
                                   "a4_a19_6"))

new.nps.6 <- nps(init.data,coeff,c("SN","respid" , "a4_a19_1",  
                                   "a4_a19_2",  "a4_a19_3",  "a4_a19_4",  "a4_a19_5",
                                   "a4_a19_6.n"))

################ Trying mlogit ###############
attach(data)
detach(data)
table(y.obs)

mldata <- mlogit.data(data, choice = "y.obs", shape = "wide")

mlogit.model <- mlogit(y.obs ~ 1 | (a4_a19_1 + a4_a19_2 + a4_a19_3 + a4_a19_4 + a4_a19_5
                                    + a4_a19_6), mldata,reflevel = "0")


summary(mlogit.model)
predicted_probab <- mlogit.model$probabilities
